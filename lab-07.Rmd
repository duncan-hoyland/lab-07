---
title: "Lab 07 - Modelling course evaluations"
author: "D Money"
date: "`r Sys.Date()`"
output: html_document
---

### Packages and Data

```{r load-packages, message=FALSE, echo=TRUE}
library(tidyverse)
library(tidymodels)

```

```{r read-data}
evals<-read.csv("data/evals.csv", row.names=1)
```

# Exercise 1: Exploratory Data Analysis

1.  Visualize the distribution of `score` in the dataframe `evals`.

```{r viz-score}
ggplot(data = evals,
       mapping = aes(x = score)) + geom_histogram(bins = 10)

evals %>% summarise(mean_score = mean(score), med_score = median(score), mode_score = mode(score), max_score = max(score), min_score = min(score))

```

Data is left skewed, more common that they rate their courses highly. Left skewed as mode > median (4.3) > mean (4.17). Expected as people are unlikely to do a course that they wont enjoy, this is seen by highest score being 5 but lowest score being only 2.3

2.  Visualize and describe the relationship between `score` and `bty_avg` using `geom_point()` to represent the data.

```{r scatterplot}
ggplot(data = evals,
       mapping = aes(x = bty_avg,
              y = score)) +
  geom_point() +
  labs(title = "with geom_point")

ggplot(data = evals,
       mapping = aes(x = bty_avg,
                     y = score)) + 
  geom_jitter() + 
  labs(title = "with geom_jitter")
```

Geom_point doesn't show if there are multiple points plotted at the exact same place, jitter moves points off one another if plotted in exact same place to account for random variation. This display of all the data and accounting for random variation gives a better understanding of the data

# Exercise 2: Simple Linear regression with a numerical predictor

1.  Fit a linear model called `score_bty_fit` to predict average professor evaluation `score` from average beauty rating (`bty_avg`). Print the regression output using `tidy()`.

```{r fit-score_bty_fit}
score_bty_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals)
```

```{r tidy-score_bty_fit}
tidy(score_bty_fit)
```

Score = 3.88 + (0.0666)(bty_avg)

2.  Plot the data again using `geom_jitter()`, and add the regression line.

```{r viz-score_bty_fit,eval=FALSE}
# add your plot here. Hint, you can add the regression line using geom_smooth()
ggplot(data = evals,
       mapping = aes(x = bty_avg,
                     y = score)) + 
  geom_jitter() + 
  geom_smooth(method = "lm", se = FALSE) + 
  labs(title = "with geom_jitter")
```

3.  Interpret the slope of the linear model in context of the data.

For every number 1 the average beauty average is the score the student give is expected to be 6.66% higher

4.  Interpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.

When the professors beauty score is zero the score the students give the course is 3.88. Makes sense as 3.88 can be the default score that students give their course, with beauty only ever making them like their course more. The value of 3.88 is less than the mean and median found earlier of 4.2 which is as expected

5.  Determine the $R^2$ of the model and interpret it in the context of the data.

```{r R2}
glance(score_bty_fit)$r.squared
```

Not a very good model as R-squared is very low, we want it to be as high as possible. Suggests there is lots of variability in score that isn't explained by the model and the expected is never very close to the observed

6.  Make a plot of residuals vs. predicted values for the model above.

```{r viz-score_bty_fit-diagnostic}
score_bty_aug <- augment(score_bty_fit$fit)

ggplot(score_bty_aug,
       mapping = aes (x = .fitted,
                      y = .resid)) + 
  geom_jitter (alpha = 0.5) +
  geom_hline(yintercept = 0,
             colour = "gray",
             lty = "dashed") + 
  labs(y = "Residuals",
       x = "Predicted Score")
```
The model is suitable as no clear patterns see in the x or y with no correlation in the predicted values


# Exercise 3: Simple Linear regression with a categorical predictor

0.  Look at the variable rank, and determine the frequency of each category level.

```{r}
evals %>% group_by(rank) %>% summarise(count = n())
```

1.  Fit a new linear model called `score_rank_fit` to predict average professor evaluation `score` based on `rank` of the professor.

```{r fit-score_rank_fit}
score_rank_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ factor(rank), data = evals)

tidy(score_rank_fit)
```

On tenure track professors are expected to be given a score 13.0% lower than teaching professors
On tenured professors are expected to be given a score 14.5% lower than teaching professors
Teaching professors on average are expected to be given a score pf 4.28 from students



2.  Fit a new linear model called `score_gender_fit` to predict average professor evaluation `score` based on `gender` of the professor.

```{r fit-score_gender_fit}
score_gender_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ factor(gender), data = evals)

tidy(score_gender_fit)
```
Female professors are expected on average to be given a score of 4.09
Male professors on average are expected to be given a score 14.1% higher than femal professors


```{r score_gender_intercept, eval=FALSE}
# remove eval = FALSE from the code chunk options
score_gender_intercept <- tidy(score_gender_fit) %>% 
  filter(term == "(Intercept)") %>%
  select(estimate) %>%
  pull()
```

```{r score_gender_slope, eval=FALSE}
# remove eval = FALSE from the code chunk options
score_gender_slope <- tidy(score_gender_fit) %>% 
  filter(term == "gendermale") %>%
  select(estimate) %>%
  pull()
```

*Add your narrative here. Use in-line code!*

# Exercise 4: Multiple linear regression

1.  Fit a multiple linear regression model, predicting average professor evaluation `score` based on average beauty rating (`bty_avg`) and `gender.`

```{r fit-score_bty_gender_fit}
# fit model

# tidy model output
```

*Add your narrative here.*

```{r eval = FALSE}
ggplot(___) + ...
```

2.  What percent of the variability in `score` is explained by the model `score_bty_gender_fit`.

```{r}
# ...
```

3.  What is the equation of the line corresponding to just male professors?

*Add your equation here.*

4.  For two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?

*Add your narrative here.*

5.  How does the relationship between beauty and evaluation score vary between male and female professors?

*Add your narrative here.*

6.  How do the adjusted $R^2$ values of `score_bty_fit` and `score_bty_gender_fit` compare?

```{r eval=FALSE}
# remove eval = FALSE from the code chunk options after filling in the blanks
glance(___)$adj.r.squared
glance(___)$adj.r.squared
```

*Add your narrative here.*

7.  Compare the slopes of `bty_avg` under the two models (`score_bty_fit` and `score_bty_gender_fit`).

*Add your narrative here.*

# Exercise 5: Interpretation of log-transformed response variables

If you do not know how to use LaTeX, do this exercise with pen and paper.
